{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "34552522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import models\n",
    "import torchvision.utils\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5697ca43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "8e7cf4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(299),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(), # ToTensor : [0, 255] -> [0, 1]\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(), # ToTensor : [0, 255] -> [0, 1]\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_data = dsets.ImageFolder('data/train/', train_transform)\n",
    "test_data = dsets.ImageFolder('data/test_model/', test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "ceb262fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_loader = DataLoader(train_data,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_data, \n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "eb6173b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, title):\n",
    "    img = torchvision.utils.make_grid(img, normalize=True)\n",
    "    npimg = img.numpy()\n",
    "    fig = plt.figure(figsize = (5, 15))\n",
    "    plt.imshow(np.transpose(npimg,(1,2,0)))\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "90637c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.inception_v3(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5c3cfc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.aux_logits = False\n",
    "\n",
    "for parameter in model.parameters():\n",
    "    parameter.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "79911974",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(model.fc.in_features, 10),\n",
    "    nn.Linear(10, 6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eab4481",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "73d332f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ab9e2cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4ff268f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], lter [5/316] Loss: 1.9105\n",
      "Epoch [1/5], lter [10/316] Loss: 1.8023\n",
      "Epoch [1/5], lter [15/316] Loss: 1.8667\n",
      "Epoch [1/5], lter [20/316] Loss: 1.8310\n",
      "Epoch [1/5], lter [25/316] Loss: 1.6655\n",
      "Epoch [1/5], lter [30/316] Loss: 1.6992\n",
      "Epoch [1/5], lter [35/316] Loss: 1.6409\n",
      "Epoch [1/5], lter [40/316] Loss: 1.7015\n",
      "Epoch [1/5], lter [45/316] Loss: 1.7497\n",
      "Epoch [1/5], lter [50/316] Loss: 1.7047\n",
      "Epoch [1/5], lter [55/316] Loss: 1.7003\n",
      "Epoch [1/5], lter [60/316] Loss: 1.7832\n",
      "Epoch [1/5], lter [65/316] Loss: 1.7006\n",
      "Epoch [1/5], lter [70/316] Loss: 1.6477\n",
      "Epoch [1/5], lter [75/316] Loss: 1.6935\n",
      "Epoch [1/5], lter [80/316] Loss: 1.6345\n",
      "Epoch [1/5], lter [85/316] Loss: 1.5078\n",
      "Epoch [1/5], lter [90/316] Loss: 1.5918\n",
      "Epoch [1/5], lter [95/316] Loss: 1.5338\n",
      "Epoch [1/5], lter [100/316] Loss: 1.6711\n",
      "Epoch [1/5], lter [105/316] Loss: 1.5689\n",
      "Epoch [1/5], lter [110/316] Loss: 1.5605\n",
      "Epoch [1/5], lter [115/316] Loss: 1.4960\n",
      "Epoch [1/5], lter [120/316] Loss: 1.7416\n",
      "Epoch [1/5], lter [125/316] Loss: 1.5401\n",
      "Epoch [1/5], lter [130/316] Loss: 1.4476\n",
      "Epoch [1/5], lter [135/316] Loss: 1.4979\n",
      "Epoch [1/5], lter [140/316] Loss: 1.4994\n",
      "Epoch [1/5], lter [145/316] Loss: 1.5374\n",
      "Epoch [1/5], lter [150/316] Loss: 1.4848\n",
      "Epoch [1/5], lter [155/316] Loss: 1.4061\n",
      "Epoch [1/5], lter [160/316] Loss: 1.4339\n",
      "Epoch [1/5], lter [165/316] Loss: 1.4334\n",
      "Epoch [1/5], lter [170/316] Loss: 1.5433\n",
      "Epoch [1/5], lter [175/316] Loss: 1.2592\n",
      "Epoch [1/5], lter [180/316] Loss: 1.3736\n",
      "Epoch [1/5], lter [185/316] Loss: 1.4027\n",
      "Epoch [1/5], lter [190/316] Loss: 1.4411\n",
      "Epoch [1/5], lter [195/316] Loss: 1.3206\n",
      "Epoch [1/5], lter [200/316] Loss: 1.4916\n",
      "Epoch [1/5], lter [205/316] Loss: 1.4238\n",
      "Epoch [1/5], lter [210/316] Loss: 1.5607\n",
      "Epoch [1/5], lter [215/316] Loss: 1.3855\n",
      "Epoch [1/5], lter [220/316] Loss: 1.2001\n",
      "Epoch [1/5], lter [225/316] Loss: 1.3047\n",
      "Epoch [1/5], lter [230/316] Loss: 1.4036\n",
      "Epoch [1/5], lter [235/316] Loss: 1.2977\n",
      "Epoch [1/5], lter [240/316] Loss: 1.3595\n",
      "Epoch [1/5], lter [245/316] Loss: 1.3324\n",
      "Epoch [1/5], lter [250/316] Loss: 1.2070\n",
      "Epoch [1/5], lter [255/316] Loss: 1.3480\n",
      "Epoch [1/5], lter [260/316] Loss: 1.3441\n",
      "Epoch [1/5], lter [265/316] Loss: 1.3002\n",
      "Epoch [1/5], lter [270/316] Loss: 1.4370\n",
      "Epoch [1/5], lter [275/316] Loss: 1.1855\n",
      "Epoch [1/5], lter [280/316] Loss: 1.3910\n",
      "Epoch [1/5], lter [285/316] Loss: 1.0103\n",
      "Epoch [1/5], lter [290/316] Loss: 1.2689\n",
      "Epoch [1/5], lter [295/316] Loss: 1.1697\n",
      "Epoch [1/5], lter [300/316] Loss: 1.2183\n",
      "Epoch [1/5], lter [305/316] Loss: 1.0959\n",
      "Epoch [1/5], lter [310/316] Loss: 1.0425\n",
      "Epoch [1/5], lter [315/316] Loss: 0.7684\n",
      "Epoch [2/5], lter [5/316] Loss: 1.2843\n",
      "Epoch [2/5], lter [10/316] Loss: 1.4814\n",
      "Epoch [2/5], lter [15/316] Loss: 1.0306\n",
      "Epoch [2/5], lter [20/316] Loss: 1.1287\n",
      "Epoch [2/5], lter [25/316] Loss: 1.2133\n",
      "Epoch [2/5], lter [30/316] Loss: 1.0984\n",
      "Epoch [2/5], lter [35/316] Loss: 1.1310\n",
      "Epoch [2/5], lter [40/316] Loss: 1.0050\n",
      "Epoch [2/5], lter [45/316] Loss: 1.0362\n",
      "Epoch [2/5], lter [50/316] Loss: 0.9934\n",
      "Epoch [2/5], lter [55/316] Loss: 0.9285\n",
      "Epoch [2/5], lter [60/316] Loss: 1.0925\n",
      "Epoch [2/5], lter [65/316] Loss: 1.0927\n",
      "Epoch [2/5], lter [70/316] Loss: 1.0732\n",
      "Epoch [2/5], lter [75/316] Loss: 0.7290\n",
      "Epoch [2/5], lter [80/316] Loss: 1.1242\n",
      "Epoch [2/5], lter [85/316] Loss: 1.1291\n",
      "Epoch [2/5], lter [90/316] Loss: 0.9400\n",
      "Epoch [2/5], lter [95/316] Loss: 0.9464\n",
      "Epoch [2/5], lter [100/316] Loss: 0.7518\n",
      "Epoch [2/5], lter [105/316] Loss: 0.9195\n",
      "Epoch [2/5], lter [110/316] Loss: 0.8666\n",
      "Epoch [2/5], lter [115/316] Loss: 1.2090\n",
      "Epoch [2/5], lter [120/316] Loss: 1.3243\n",
      "Epoch [2/5], lter [125/316] Loss: 0.9756\n",
      "Epoch [2/5], lter [130/316] Loss: 1.0556\n",
      "Epoch [2/5], lter [135/316] Loss: 1.0780\n",
      "Epoch [2/5], lter [140/316] Loss: 0.8734\n",
      "Epoch [2/5], lter [145/316] Loss: 0.9741\n",
      "Epoch [2/5], lter [150/316] Loss: 1.0890\n",
      "Epoch [2/5], lter [155/316] Loss: 1.0280\n",
      "Epoch [2/5], lter [160/316] Loss: 0.9799\n",
      "Epoch [2/5], lter [165/316] Loss: 0.7681\n",
      "Epoch [2/5], lter [170/316] Loss: 0.9594\n",
      "Epoch [2/5], lter [175/316] Loss: 0.7743\n",
      "Epoch [2/5], lter [180/316] Loss: 0.8418\n",
      "Epoch [2/5], lter [185/316] Loss: 0.9052\n",
      "Epoch [2/5], lter [190/316] Loss: 1.1379\n",
      "Epoch [2/5], lter [195/316] Loss: 0.7769\n",
      "Epoch [2/5], lter [200/316] Loss: 0.8736\n",
      "Epoch [2/5], lter [205/316] Loss: 0.9277\n",
      "Epoch [2/5], lter [210/316] Loss: 0.8450\n",
      "Epoch [2/5], lter [215/316] Loss: 0.9136\n",
      "Epoch [2/5], lter [220/316] Loss: 0.8733\n",
      "Epoch [2/5], lter [225/316] Loss: 0.9119\n",
      "Epoch [2/5], lter [230/316] Loss: 0.9769\n",
      "Epoch [2/5], lter [235/316] Loss: 1.3397\n",
      "Epoch [2/5], lter [240/316] Loss: 0.9071\n",
      "Epoch [2/5], lter [245/316] Loss: 0.8283\n",
      "Epoch [2/5], lter [250/316] Loss: 0.6389\n",
      "Epoch [2/5], lter [255/316] Loss: 1.0155\n",
      "Epoch [2/5], lter [260/316] Loss: 1.2929\n",
      "Epoch [2/5], lter [265/316] Loss: 0.7094\n",
      "Epoch [2/5], lter [270/316] Loss: 0.9456\n",
      "Epoch [2/5], lter [275/316] Loss: 0.9836\n",
      "Epoch [2/5], lter [280/316] Loss: 1.0365\n",
      "Epoch [2/5], lter [285/316] Loss: 1.1263\n",
      "Epoch [2/5], lter [290/316] Loss: 1.3234\n",
      "Epoch [2/5], lter [295/316] Loss: 0.7374\n",
      "Epoch [2/5], lter [300/316] Loss: 0.9017\n",
      "Epoch [2/5], lter [305/316] Loss: 0.6271\n",
      "Epoch [2/5], lter [310/316] Loss: 0.6993\n",
      "Epoch [2/5], lter [315/316] Loss: 0.6291\n",
      "Epoch [3/5], lter [5/316] Loss: 1.0665\n",
      "Epoch [3/5], lter [10/316] Loss: 1.1748\n",
      "Epoch [3/5], lter [15/316] Loss: 0.6423\n",
      "Epoch [3/5], lter [20/316] Loss: 0.6538\n",
      "Epoch [3/5], lter [25/316] Loss: 0.8371\n",
      "Epoch [3/5], lter [30/316] Loss: 0.9592\n",
      "Epoch [3/5], lter [35/316] Loss: 0.7561\n",
      "Epoch [3/5], lter [40/316] Loss: 0.8152\n",
      "Epoch [3/5], lter [45/316] Loss: 0.5665\n",
      "Epoch [3/5], lter [50/316] Loss: 0.7515\n",
      "Epoch [3/5], lter [55/316] Loss: 0.8421\n",
      "Epoch [3/5], lter [60/316] Loss: 0.6087\n",
      "Epoch [3/5], lter [65/316] Loss: 0.6053\n",
      "Epoch [3/5], lter [70/316] Loss: 1.6521\n",
      "Epoch [3/5], lter [75/316] Loss: 0.8503\n",
      "Epoch [3/5], lter [80/316] Loss: 0.8598\n",
      "Epoch [3/5], lter [85/316] Loss: 0.6804\n",
      "Epoch [3/5], lter [90/316] Loss: 0.7159\n",
      "Epoch [3/5], lter [95/316] Loss: 0.7590\n",
      "Epoch [3/5], lter [100/316] Loss: 0.5854\n",
      "Epoch [3/5], lter [105/316] Loss: 0.3536\n",
      "Epoch [3/5], lter [110/316] Loss: 0.7905\n",
      "Epoch [3/5], lter [115/316] Loss: 0.3669\n",
      "Epoch [3/5], lter [120/316] Loss: 0.6993\n",
      "Epoch [3/5], lter [125/316] Loss: 0.6779\n",
      "Epoch [3/5], lter [130/316] Loss: 0.8685\n",
      "Epoch [3/5], lter [135/316] Loss: 0.8553\n",
      "Epoch [3/5], lter [140/316] Loss: 0.5374\n",
      "Epoch [3/5], lter [145/316] Loss: 0.5029\n",
      "Epoch [3/5], lter [150/316] Loss: 0.4507\n",
      "Epoch [3/5], lter [155/316] Loss: 0.8291\n",
      "Epoch [3/5], lter [160/316] Loss: 0.3774\n",
      "Epoch [3/5], lter [165/316] Loss: 0.7581\n",
      "Epoch [3/5], lter [170/316] Loss: 0.5498\n",
      "Epoch [3/5], lter [175/316] Loss: 0.5623\n",
      "Epoch [3/5], lter [180/316] Loss: 0.9718\n",
      "Epoch [3/5], lter [185/316] Loss: 0.5605\n",
      "Epoch [3/5], lter [190/316] Loss: 0.4902\n",
      "Epoch [3/5], lter [195/316] Loss: 0.5181\n",
      "Epoch [3/5], lter [200/316] Loss: 0.6802\n",
      "Epoch [3/5], lter [205/316] Loss: 0.3636\n",
      "Epoch [3/5], lter [210/316] Loss: 0.4657\n",
      "Epoch [3/5], lter [215/316] Loss: 0.7174\n",
      "Epoch [3/5], lter [220/316] Loss: 0.5263\n",
      "Epoch [3/5], lter [225/316] Loss: 0.7080\n",
      "Epoch [3/5], lter [230/316] Loss: 0.5563\n",
      "Epoch [3/5], lter [235/316] Loss: 0.6619\n",
      "Epoch [3/5], lter [240/316] Loss: 0.4134\n",
      "Epoch [3/5], lter [245/316] Loss: 0.6878\n",
      "Epoch [3/5], lter [250/316] Loss: 0.4579\n",
      "Epoch [3/5], lter [255/316] Loss: 0.4888\n",
      "Epoch [3/5], lter [260/316] Loss: 0.6423\n",
      "Epoch [3/5], lter [265/316] Loss: 0.5423\n",
      "Epoch [3/5], lter [270/316] Loss: 0.4057\n",
      "Epoch [3/5], lter [275/316] Loss: 0.5164\n",
      "Epoch [3/5], lter [280/316] Loss: 0.6027\n",
      "Epoch [3/5], lter [285/316] Loss: 0.2766\n",
      "Epoch [3/5], lter [290/316] Loss: 0.4451\n",
      "Epoch [3/5], lter [295/316] Loss: 0.7343\n",
      "Epoch [3/5], lter [300/316] Loss: 0.5282\n",
      "Epoch [3/5], lter [305/316] Loss: 0.6341\n",
      "Epoch [3/5], lter [310/316] Loss: 0.6445\n",
      "Epoch [3/5], lter [315/316] Loss: 0.3325\n",
      "Epoch [4/5], lter [5/316] Loss: 0.3779\n",
      "Epoch [4/5], lter [10/316] Loss: 0.5371\n",
      "Epoch [4/5], lter [15/316] Loss: 0.7315\n",
      "Epoch [4/5], lter [20/316] Loss: 0.7479\n",
      "Epoch [4/5], lter [25/316] Loss: 0.4539\n",
      "Epoch [4/5], lter [30/316] Loss: 0.8055\n",
      "Epoch [4/5], lter [35/316] Loss: 0.5779\n",
      "Epoch [4/5], lter [40/316] Loss: 0.5726\n",
      "Epoch [4/5], lter [45/316] Loss: 0.5368\n",
      "Epoch [4/5], lter [50/316] Loss: 0.5209\n",
      "Epoch [4/5], lter [55/316] Loss: 0.6570\n",
      "Epoch [4/5], lter [60/316] Loss: 0.8098\n",
      "Epoch [4/5], lter [65/316] Loss: 0.3760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], lter [70/316] Loss: 0.5053\n",
      "Epoch [4/5], lter [75/316] Loss: 0.3720\n",
      "Epoch [4/5], lter [80/316] Loss: 0.5637\n",
      "Epoch [4/5], lter [85/316] Loss: 0.5622\n",
      "Epoch [4/5], lter [90/316] Loss: 0.8412\n",
      "Epoch [4/5], lter [95/316] Loss: 0.6389\n",
      "Epoch [4/5], lter [100/316] Loss: 0.4827\n",
      "Epoch [4/5], lter [105/316] Loss: 0.7669\n",
      "Epoch [4/5], lter [110/316] Loss: 0.2936\n",
      "Epoch [4/5], lter [115/316] Loss: 0.3328\n",
      "Epoch [4/5], lter [120/316] Loss: 0.7674\n",
      "Epoch [4/5], lter [125/316] Loss: 0.7232\n",
      "Epoch [4/5], lter [130/316] Loss: 0.3944\n",
      "Epoch [4/5], lter [135/316] Loss: 0.5200\n",
      "Epoch [4/5], lter [140/316] Loss: 0.5391\n",
      "Epoch [4/5], lter [145/316] Loss: 0.6498\n",
      "Epoch [4/5], lter [150/316] Loss: 0.3991\n",
      "Epoch [4/5], lter [155/316] Loss: 0.4445\n",
      "Epoch [4/5], lter [160/316] Loss: 0.3599\n",
      "Epoch [4/5], lter [165/316] Loss: 0.7480\n",
      "Epoch [4/5], lter [170/316] Loss: 0.6339\n",
      "Epoch [4/5], lter [175/316] Loss: 0.3822\n",
      "Epoch [4/5], lter [180/316] Loss: 0.4783\n",
      "Epoch [4/5], lter [185/316] Loss: 0.4789\n",
      "Epoch [4/5], lter [190/316] Loss: 0.5499\n",
      "Epoch [4/5], lter [195/316] Loss: 0.8504\n",
      "Epoch [4/5], lter [200/316] Loss: 0.7647\n",
      "Epoch [4/5], lter [205/316] Loss: 0.9674\n",
      "Epoch [4/5], lter [210/316] Loss: 0.4685\n",
      "Epoch [4/5], lter [215/316] Loss: 0.4805\n",
      "Epoch [4/5], lter [220/316] Loss: 0.4698\n",
      "Epoch [4/5], lter [225/316] Loss: 0.5795\n",
      "Epoch [4/5], lter [230/316] Loss: 0.6851\n",
      "Epoch [4/5], lter [235/316] Loss: 0.6667\n",
      "Epoch [4/5], lter [240/316] Loss: 0.6685\n",
      "Epoch [4/5], lter [245/316] Loss: 0.3757\n",
      "Epoch [4/5], lter [250/316] Loss: 0.3174\n",
      "Epoch [4/5], lter [255/316] Loss: 0.4902\n",
      "Epoch [4/5], lter [260/316] Loss: 0.7395\n",
      "Epoch [4/5], lter [265/316] Loss: 0.4542\n",
      "Epoch [4/5], lter [270/316] Loss: 0.9709\n",
      "Epoch [4/5], lter [275/316] Loss: 0.4318\n",
      "Epoch [4/5], lter [280/316] Loss: 0.3032\n",
      "Epoch [4/5], lter [285/316] Loss: 0.7661\n",
      "Epoch [4/5], lter [290/316] Loss: 0.9021\n",
      "Epoch [4/5], lter [295/316] Loss: 0.9998\n",
      "Epoch [4/5], lter [300/316] Loss: 0.4271\n",
      "Epoch [4/5], lter [305/316] Loss: 0.9158\n",
      "Epoch [4/5], lter [310/316] Loss: 0.1794\n",
      "Epoch [4/5], lter [315/316] Loss: 0.6658\n",
      "Epoch [5/5], lter [5/316] Loss: 0.8250\n",
      "Epoch [5/5], lter [10/316] Loss: 0.4392\n",
      "Epoch [5/5], lter [15/316] Loss: 0.3536\n",
      "Epoch [5/5], lter [20/316] Loss: 0.7605\n",
      "Epoch [5/5], lter [25/316] Loss: 0.4892\n",
      "Epoch [5/5], lter [30/316] Loss: 0.7135\n",
      "Epoch [5/5], lter [35/316] Loss: 0.6169\n",
      "Epoch [5/5], lter [40/316] Loss: 0.9326\n",
      "Epoch [5/5], lter [45/316] Loss: 0.5228\n",
      "Epoch [5/5], lter [50/316] Loss: 0.5898\n",
      "Epoch [5/5], lter [55/316] Loss: 0.5605\n",
      "Epoch [5/5], lter [60/316] Loss: 0.4257\n",
      "Epoch [5/5], lter [65/316] Loss: 0.9673\n",
      "Epoch [5/5], lter [70/316] Loss: 0.5095\n",
      "Epoch [5/5], lter [75/316] Loss: 0.9344\n",
      "Epoch [5/5], lter [80/316] Loss: 0.3506\n",
      "Epoch [5/5], lter [85/316] Loss: 1.0719\n",
      "Epoch [5/5], lter [90/316] Loss: 0.5665\n",
      "Epoch [5/5], lter [95/316] Loss: 0.3509\n",
      "Epoch [5/5], lter [100/316] Loss: 0.4701\n",
      "Epoch [5/5], lter [105/316] Loss: 0.5215\n",
      "Epoch [5/5], lter [110/316] Loss: 0.5385\n",
      "Epoch [5/5], lter [115/316] Loss: 0.3123\n",
      "Epoch [5/5], lter [120/316] Loss: 1.1485\n",
      "Epoch [5/5], lter [125/316] Loss: 0.4438\n",
      "Epoch [5/5], lter [130/316] Loss: 0.4352\n",
      "Epoch [5/5], lter [135/316] Loss: 0.6626\n",
      "Epoch [5/5], lter [140/316] Loss: 0.3905\n",
      "Epoch [5/5], lter [145/316] Loss: 0.6018\n",
      "Epoch [5/5], lter [150/316] Loss: 0.7225\n",
      "Epoch [5/5], lter [155/316] Loss: 0.2752\n",
      "Epoch [5/5], lter [160/316] Loss: 0.9176\n",
      "Epoch [5/5], lter [165/316] Loss: 0.5607\n",
      "Epoch [5/5], lter [170/316] Loss: 0.4890\n",
      "Epoch [5/5], lter [175/316] Loss: 0.6267\n",
      "Epoch [5/5], lter [180/316] Loss: 0.9164\n",
      "Epoch [5/5], lter [185/316] Loss: 0.4004\n",
      "Epoch [5/5], lter [190/316] Loss: 0.4443\n",
      "Epoch [5/5], lter [195/316] Loss: 0.2403\n",
      "Epoch [5/5], lter [200/316] Loss: 0.4694\n",
      "Epoch [5/5], lter [205/316] Loss: 0.6275\n",
      "Epoch [5/5], lter [210/316] Loss: 0.4477\n",
      "Epoch [5/5], lter [215/316] Loss: 0.3689\n",
      "Epoch [5/5], lter [220/316] Loss: 0.5312\n",
      "Epoch [5/5], lter [225/316] Loss: 0.5766\n",
      "Epoch [5/5], lter [230/316] Loss: 0.1209\n",
      "Epoch [5/5], lter [235/316] Loss: 0.3073\n",
      "Epoch [5/5], lter [240/316] Loss: 0.5315\n",
      "Epoch [5/5], lter [245/316] Loss: 0.5321\n",
      "Epoch [5/5], lter [250/316] Loss: 0.3322\n",
      "Epoch [5/5], lter [255/316] Loss: 0.4489\n",
      "Epoch [5/5], lter [260/316] Loss: 0.5773\n",
      "Epoch [5/5], lter [265/316] Loss: 0.6193\n",
      "Epoch [5/5], lter [270/316] Loss: 0.5051\n",
      "Epoch [5/5], lter [275/316] Loss: 0.3229\n",
      "Epoch [5/5], lter [280/316] Loss: 0.4376\n",
      "Epoch [5/5], lter [285/316] Loss: 0.4225\n",
      "Epoch [5/5], lter [290/316] Loss: 0.9904\n",
      "Epoch [5/5], lter [295/316] Loss: 0.6402\n",
      "Epoch [5/5], lter [300/316] Loss: 0.2784\n",
      "Epoch [5/5], lter [305/316] Loss: 0.3282\n",
      "Epoch [5/5], lter [310/316] Loss: 0.8067\n",
      "Epoch [5/5], lter [315/316] Loss: 0.5359\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    total_batch = len(train_data)//batch_size\n",
    "\n",
    "    for i, (batch_images, batch_labels) in enumerate(train_loader):\n",
    "#         print(batch_images)\n",
    "#         print(batch_labels)\n",
    "        X = batch_images#.cuda()\n",
    "        Y = batch_labels#.cuda()\n",
    "\n",
    "        pre = model(X)\n",
    "        cost = loss(pre, Y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 5 == 0:\n",
    "            print('Epoch [%d/%d], lter [%d/%d] Loss: %.4f'\n",
    "                 %(epoch+1, num_epochs, i+1, total_batch, cost.item()))\n",
    "            \n",
    "torch.save(model.state_dict(), \"modelTorch.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "5bd649f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test images: 91.600000 %\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    \n",
    "#     images = images.cuda()\n",
    "    outputs = model(images)\n",
    "    \n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "    \n",
    "print('Accuracy of test images: %f %%' % (100 * float(correct) / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c71da49",
   "metadata": {},
   "source": [
    "# The scripts below: To be continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "1a9c994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(test_loader):\n",
    "            inputs = inputs#.to(device)\n",
    "            labels = labels#.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'predicted: {classes[preds[j]]}')\n",
    "                imshow(inputs.cpu().data[j], 'test')\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "a9b8db69",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict() missing 2 required positional arguments: 'device' and 'encoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3604\\2441693545.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mface\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mface\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: predict() missing 2 required positional arguments: 'device' and 'encoder'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "frame = cv2.imread('./data/test_model/client008/5.jpg')\n",
    "def face_detector(img, size=0.5):\n",
    "\n",
    "    # Convert image to grayscale\n",
    "#     gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "#     faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if len(faces) == None:\n",
    "        print(\"Empty\")\n",
    "        return img, []\n",
    "    print(\"NotEmpty\", faces)\n",
    "    for (x,y,w,h) in faces:\n",
    "        \n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (224, 224))\n",
    "    return img, roi\n",
    "\n",
    "# im, f = face_detector(frame)\n",
    "face = Image.fromarray(frame)\n",
    "image = Image.fromarray(im)\n",
    "predict(model,face)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672c35c5",
   "metadata": {},
   "source": [
    "##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b71b5a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['client001', 'client002', 'client004', 'client006', 'client007', 'client008']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = [\"client001\", \"client002\", \"client004\", \"client006\", \"client007\", \"client008\"]\n",
    "classes = os.listdir('./data/test_model')\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "793828fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3604\\2507298866.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./data/test_model/client001/2.jpg'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ai\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ai\\lib\\site-packages\\torchvision\\models\\inception.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mInceptionOutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[0maux_defined\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maux_logits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ai\\lib\\site-packages\\torchvision\\models\\inception.py\u001b[0m in \u001b[0;36m_transform_input\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_transform_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m             \u001b[0mx_ch0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0.229\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0.485\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m             \u001b[0mx_ch1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0.224\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0.456\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[0mx_ch2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0.225\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0.406\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "classes = [\"client001\", \"client002\", \"client004\", \"client006\", \"client007\", \"client008\"]\n",
    "es, labels = next(iter(test_loader))\n",
    "images = './data/test_model/client001/2.jpg'\n",
    "outputs = model(images)\n",
    "\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(5)))\n",
    "\n",
    "title = (' '.join('%5s' % classes[labels[j]] for j in range(5)))\n",
    "imshow(torchvision.utils.make_grid(images, normalize=True), title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9c41b831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.save(model, 'modelTorch.pt')\n",
    "# model = torch.load('modelTorch.pt')\n",
    "# print(type(model))\n",
    "# model.eval()\n",
    "# \n",
    "# load your model architecture/module\n",
    "# model = Inecption3()\n",
    "# fill your architecture with the trained weights\n",
    "model.load_state_dict(torch.load(\"modelTorch.pt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
